## Превращение однопоточного сервера в многопоточный сервер

В текущей реализации сервер обрабатывает каждый запрос по очереди, то есть, он не начнёт обрабатывать второе соединение, пока не завершит обработку первого. При росте числа запросов к серверу, такое последовательное выполнение было бы все менее и менее разумным. Если сервер получает какой-то запрос, обработка которого занимает достаточно много времени, последующим запросам придётся ждать завершения обработки длительного запроса, даже если эти новые запросы сами по себе могут быть обработаны быстро. Нам нужно это исправить, но сначала рассмотрим неполадку в действии.

### Подражание медленного запроса в текущей реализации сервера

Мы посмотрим, как запрос с медленной обработкой может повлиять на другие запросы, сделанные к серверу в текущей реализации. В приложении 20-10 реализована обработка запроса к ресурсу */sleep* с эмуляцией медленного ответа, при которой сервер будет ждать 5 секунд перед тем, как ответить.

<span class="filename">Файл: src/main.rs</span>

```rust,no_run
{{#rustdoc_include ../listings/ch20-web-server/listing-20-10/src/main.rs:here}}
```

<span class="caption">Приложение 20-10: Подражание медленного запроса с помощью 5-секундной задержки</span>

Мы переключились с `if` на `match`, так как теперь у нас есть три случая. Нам придётся явно сопоставить срез от `request_line` для проверки совпадения шаблона со строковыми записями; `match` не делает самостоятельно е ссылки и разыменования, как это делает способ равенства.

Первая ветка совпадает с разделом `if` из приложения 20-9. Вторая ветка соответствует запросу */sleep* . Когда этот запрос получен, сервер заснёт на 5 секунд, прежде чем отдать успешную HTML-страницу. Третья ветка совпадает с разделом `else` из приложения 20-9.

Можно увидеть, насколько прост наш сервер: в существующих библиотеках распознавание разных запросов осуществлялось бы гораздо менее многословно!

Запустите сервер приказом `cargo run`. Затем откройте два окна браузера: одно с адресом *http://127.0.0.1:7878/*, другое с *http://127.0.0.1:7878/sleep*. Если вы несколько раз обратитесь к URI */*, то как и раньше увидите, что сервер быстро ответит. Но если вы введёте URI */sleep*, а затем загрузите URI */*, то увидите что */* ждёт, пока `/sleep` не отработает полные 5 секунд перед загрузкой страницы.

Есть несколько способов, которые можно использовать, чтобы избавиться от подтормаживания запросов после одного медленного запроса; способ, который мы реализуем, называется объединением потоков.

### Улучшение пропускной способности с помощью объединения потоков

*Объединение потоков* является группой заранее порождённых потоков, ожидающих в объединении и готовых выполнить задачу. Когда программа получает новую задачу, она назначает эту задачу одному из потоков в объединении, и тогда задача будет обработана этим потоком. Остальные потоки в объединении доступны для обработки любых других задач, поступающих в то время, пока первый поток занят. Когда первый поток завершает обработку своей задачи, он возвращается в объединениесвободных потоков, готовых приступить к новой задаче. Объединение потоков позволяет обрабатывать соединения одновременно, увеличивая пропускную способность вашего сервера.

Мы ограничим число потоков в объединении небольшим числом, чтобы защитить нас от атак вида «отказ в обслуживании» (DoS - Denial of Service); если бы наша программа создавала новый поток в мгновение поступления каждого запроса, то кто-то сделавший 10 миллионов запросов к серверу, мог бы создать хаос, использовать все ресурсы нашего сервера и остановить обработку запросов.

Вместо порождения неограниченного количества потоков, у нас будет определенное количество потоков, ожидающих в объединении. Поступающие запросы будут отправляться в объединениедля обработки. Объединение будет иметь очередь входящих запросов. Каждый из потоков в объединении будет извлекать запрос из этой очереди, обрабатывать запрос и затем запрашивать в очереди следующий запрос. При таком внешнем виде мы можем обрабатывать `N` запросов одновременно, где `N` - количество потоков. Если каждый поток отвечает на длительный запрос, последующие запросы могут по-прежнему задержаться в очереди, но теперь мы увеличили количество "длинных" запросов, которые мы можем обработать, перед тем, как эта случаей снова возникнет.

Этот подход - лишь один из многих способов улучшить пропускную способность веб-сервера. Другими вариантами, на которые возможно стоило бы обратить внимание, являются: *прообраз fork/join*, *прообраз однопоточного не согласованного ввода-вывода* или *прообраз многопоточного не согласованного ввода-вывода*. Если вам важна эта тема, вы можете почитать больше сведений о других решениях и попробовать реализовать их самостоятельно. С таким низкоуровневым языком как Rust, любой из этих вариантов осуществим.

Прежде чем приступить к реализации объединения потоков, давайте поговорим о том, как должно выглядеть использование объединения . Когда вы пытаетесь проектировать код, сначала необходимо написать клиентский внешнюю оболочку. Напишите API кода, чтобы он был структурирован так, как вы хотите его вызывать, затем реализуйте функциональность данной структуры, вместо подхода реализовывать функционал, а затем разрабатывать общедоступный API.

Подобно тому, как мы использовали разработку через проверка (test-driven) в проекте главы 12, мы будем использовать здесь разработку, управляемую сборщиком (compiler-driven). Мы напишем код, вызывающий нужные нам функции, а затем посмотрим на ошибки сборщика, чтобы определить, что мы должны изменить дальше, чтобы заставить код работать. Однако перед этим, в качестве отправной точки, мы рассмотрим технику, которую мы не будем применять в дальнейшем.

<!-- Old headings. Do not remove or links may break. -->

<a id="code-structure-if-we-could-spawn-a-thread-for-each-request"></a>

#### Порождение потока для каждого запроса

Сначала давайте рассмотрим, как мог бы выглядеть код, если бы он создавал бы новый поток для каждого соединения. Как упоминалось ранее, мы не собираемся использовать этот способ в окончательной реализации, из-за возможных неполадок при возможно неограниченном числе порождённых потоков. Это лишь отправная точка, с которой начнёт работу наш многопоточный сервер. Затем мы улучшим код, добавив объединениепотоков, и тогда разницу между этими двумя решениями будет легче заметить. В приложении 20-11 показаны изменения, которые нужно внести в код `main`, чтобы порождать новый поток для обработки каждого входящего соединения внутри цикла `for`.

<span class="filename">Файл: src/main.rs</span>

```rust,no_run
{{#rustdoc_include ../listings/ch20-web-server/listing-20-11/src/main.rs:here}}
```

<span class="caption">Приложение 20-11: Порождение нового потока для каждого соединения</span>

Как вы изучили в главе 16, функция `thread::spawn` создаст новый поток и затем запустит код замыкания в этом новом потоке. Если вы запустите этот код и загрузите */sleep* в своём браузере, а затем загрузите */* в двух других вкладках браузера, вы действительно увидите, что запросам к */* не приходится ждать завершения */sleep*. Но, как мы уже упоминали, это в какой-то мгновение приведёт к сильному снижению производительности системы, так как вы будете создавать новые потоки без каких-либо ограничений.

<!-- Old headings. Do not remove or links may break. -->

<a id="creating-a-similar-interface-for-a-finite-number-of-threads"></a>

#### Создание конечного числа потоков

Мы хотим, чтобы наш объединениепотоков работал подобным, знакомым образом, чтобы переключение с потоков на объединениепотоков не требовало больших изменений в коде использующем наш API. В приложении 20-12 показан гипотетический внешняя оболочка для структуры `ThreadPool`, который мы хотим использовать вместо `thread::spawn`.

<span class="filename">Файл: src/main.rs</span>

```rust,ignore,does_not_compile
{{#rustdoc_include ../listings/ch20-web-server/listing-20-12/src/main.rs:here}}
```

<span class="caption">Приложение 20-12: Наш наилучший внешняя оболочка <code>ThreadPool</code></span>

Мы используем `ThreadPool::new`, чтобы создать новый объединениепотоков с конфигурируемым числом потоков, в данном случае четырьмя. Затем в цикле `for` функция `pool.execute` имеет внешнюю оболочку, похожий на `thread::spawn`, в том смысле, что он так же принимает замыкание, код которого объединениедолжен выполнить для каждого соединения. Нам нужно реализовать `pool.execute`, чтобы он принимал замыкание и передавал его потоку из объединения для выполнения. Этот код пока не ссобирается, но мы постараемся, чтобы сборщик помог нам это исправить.

<!-- Old headings. Do not remove or links may break. -->

<a id="building-the-threadpool-struct-using-compiler-driven-development"></a>

#### Создание `ThreadPool` с помощью разработки, управляемой сборщиком

Внесите изменения приложения 20-12 в файл *src/main.rs*, а затем давайте воспользуемся ошибками сборщика из приказы `cargo check` для управления нашей разработкой. Вот первая ошибка, которую мы получаем:

```console
{{#include ../listings/ch20-web-server/listing-20-12/output.txt}}
```

Замечательно! Ошибка говорит о том, что нам нужен вид или модуль `ThreadPool`, поэтому мы сейчас его создадим. Наша реализация `ThreadPool` не будет зависеть от того, что делает наш веб-сервер. Итак, давайте переделаем ящик `hello` из двоичного в библиотечный, чтобы хранить там нашу реализацию `ThreadPool`. После того, как мы переключимся в библиотечный ящик, мы также сможем использовать отдельную библиотеку объединения потоков для любой подходящей работы, а не только для обслуживания веб-запросов.

Создайте файл *src/lib.rs*, который содержит следующий код, который является простейшим определением структуры `ThreadPool`, которое мы можем иметь на данный мгновение:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/src/lib.rs}}
```

Затем изменените файл *main.rs*, чтобы внести `ThreadPool`  из библиотечного ящика в текущую область видимости, добавив следующий код в начало *src/main.rs*:

<span class="filename">Файл: src/main.rs</span>

```rust,ignore
{{#rustdoc_include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/src/main.rs:here}}
```

Этот код по-прежнему не будет работать, но давайте проверим его ещё раз, чтобы получить следующую ошибку, которую нам нужно устранить:

```console
{{#include ../listings/ch20-web-server/no-listing-01-define-threadpool-struct/output.txt}}
```

Эта ошибка указывает, что далее нам нужно создать сопряженную функцию с именем `new` для `ThreadPool`. Мы также знаем, что `new` должна иметь один свойство, который может принимать `4` в качестве переменной и должен возвращать образец `ThreadPool`. Давайте реализуем простейшую функцию `new`, которая будет иметь эти свойства:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-02-impl-threadpool-new/src/lib.rs}}
```

Мы выбираем `usize` в качестве вида свойства `size`, потому что мы знаем, что отрицательное число потоков не имеет никакого смысла. Мы также знаем, что мы будем использовать число 4 в качестве количества элементов в собрания потоков, для чего предназначен вид `usize`, как обсуждалось в разделе ["Целочисленные виды"]<!--  --> главы 3.

Давайте проверим код ещё раз:

```console
{{#include ../listings/ch20-web-server/no-listing-02-impl-threadpool-new/output.txt}}
```

Теперь мы ошибка возникает из-за того, что у нас нет способа `execute` в структуре `ThreadPool`. Вспомните раздел ["Создание конечного числа потоков"](#creating-a-finite-number-of-threads)<!-- ignore -->, в котором мы решили, что наш объединениепотоков должен иметь внешнюю оболочку, похожий на `thread::spawn`. Кроме того, мы реализуем функцию `execute`, чтобы она принимала замыкание и передавала его свободному потоку из объединения для запуска.

Мы определим способ `execute` у `ThreadPool`, принимающий замыкание в качестве свойства. Вспомните из раздела ["Перемещение захваченных значений из замыканий и особенности `Fn`"](ch13-01-closures.html#moving-captured-values-out-of-the-closure-and-the-fn-traits) <!-- ignore --> главы 13 сведения о том, что мы можем принимать замыкания в качестве свойств тремя различными типажами: `Fn` , `FnMut` и `FnOnce`. Нам нужно решить, какой вид замыкания использовать здесь. Мы знаем, что в конечном счёте мы сделаем что-то похожее на реализацию встроенной библиотеки `thread::spawn`, поэтому мы можем посмотреть, какие ограничения накладывает на свой свойство ярлык функции `thread::spawn`. Документация показывает следующее:

```rust,ignore
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

Свойство вида `F` - это как раз то, что нас важно; свойство вида `T` относится к возвращаемому значению и нам он не важен. Можно увидеть, что `spawn` использует `FnOnce` в качестве ограничения типажа у `F`. Возможно это как раз то, чего мы хотим, так как в конечном итоге мы передадим полученный в `execute` переменная в функцию `spawn`. Дополнительную уверенность в том, что `FnOnce` - это именно тот типаж, который мы хотим использовать, нам даётобстоятельство, что поток для выполнения запроса будет выполнять замыкание этого запроса только один раз, что соответствует части  `Once` ("единожды") в названии типажа `FnOnce`.

Свойство вида `F` также имеет ограничение типажа `Send` и ограничение времени жизни `'static`, которые полезны в нашей случаи: нам нужен `Send` для передачи замыкания из одного потока в другой и `'static`, потому что мы не знаем, сколько времени поток будет выполняться. Давайте создадим способ `execute` для `ThreadPool`, который будет принимать обобщённый свойство вида `F` со следующими ограничениями:

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/no-listing-03-define-execute/src/lib.rs:here}}
```

Мы по-прежнему используем `()` после `FnOnce` потому что типаж `FnOnce` представляет замыкание, которое не принимает свойств и возвращает единичный вид `()`. Также как и при определении функций, вид возвращаемого значения в ярлыке может быть опущен, но даже если у нас нет свойств, нам все равно нужны скобки.

Опять же, это самая простая реализация способа `execute`: она ничего не делает, мы просто пытаемся сделать код собираемым. Давайте проверим снова:

```console
{{#include ../listings/ch20-web-server/no-listing-03-define-execute/output.txt}}
```

Сейчас мы получаем только предупреждения, что означает, что код собирается! Но обратите внимание, если вы попробуете `cargo run` и сделаете запрос в браузере, вы увидите ошибки в браузере, которые мы видели в начале главы. Наша библиотека на самом деле ещё не вызывает замыкание, переданное в `execute`!

> Примечание: вы возможно слышали высказывание о языках со строгими сборщиками, таких как Haskell и Rust, которое звучит так: «Если код собирается, то он работает». Но это высказывание не всегда верно. Наш проект собирается, но абсолютно ничего не делает! Если бы мы создавали существующий, законченный проект, это был бы хороший мгновение начать писать модульные проверки, чтобы проверять, что код собирается *и* имеет желаемое поведение.

#### Проверка количества потоков в `new`

Мы ничего не делаем с свойствами `new` и `execute`. Давайте реализуем тела этих функций с нужным нам поведением. Для начала давайте подумаем о `new`. Ранее мы выбрали беззнаковый вид для свойства `size`, потому что объединениес отрицательным числом потоков не имеет смысла. Объединение с нулём потоков также не имеет смысла, однако ноль - это вполне допустимое значение `usize`. Мы добавим код для проверки того, что `size` больше нуля, прежде чем вернуть образец `ThreadPool`, и заставим программу паниковать, если она получит ноль, используя макрос `assert!`, как показано в приложении 20-13.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-13/src/lib.rs:here}}
```

<span class="caption">Приложение 20-13: Реализация <code>ThreadPool::new</code> с со сбоем завершениям работы, если <code>size</code> равен нулю</span>

Мы добавили немного документации для нашей структуры `ThreadPool` с помощью примечаниев. Обратите внимание, что мы следовали хорошим применением документирования, добавив раздел, в котором указывается случаей, при которой функция может со сбоем завершаться, как это обсуждалось в главе 14. Попробуйте запустить `cargo doc --open` и кликнуть на структуру `ThreadPool`, чтобы увидеть как выглядит созданная документация для `new`!

Вместо добавления макроса `assert!`, как мы здесь сделали, мы могли бы преобразовать функцию `new` в функцию `build` таким образом, чтобы она возвращала `Result` , подобно тому, как мы делали в функции `Config::new` проекта ввода/вывода в приложении 12-9. Но в данном случае мы решили, что попытка создания объединения потоков без указания хотя бы одного потока должна быть непоправимой ошибкой. Если вы чувствуете такое стремление, попробуйте написать функцию `build`  с ярлыком ниже, для сравнения с функцией `new`:

```rust,ignore
pub fn build(size: usize) -> Result<ThreadPool, PoolCreationError> {
```

#### Создание места для хранения потоков

Теперь, имея возможность удостовериться, что количество потоков для хранения в объединении соответствует требованиям, мы можем создавать эти потоки и сохранять их в структуре `ThreadPool` перед тем как возвратить её. Но как мы "сохраним" поток? Давайте ещё раз посмотрим на ярлык `thread::spawn`:

```rust,ignore
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T,
        F: Send + 'static,
        T: Send + 'static,
```

Функция `spawn` возвращает вид `JoinHandle<T>`, где `T` является видом, который возвращает замыкание. Давайте попробуем использовать `JoinHandle` и посмотрим, что произойдёт. В нашем случае замыкания, которые мы передаём объединению потоков, будут обрабатывать соединение и не будут возвращать ничего, поэтому `T` будет единичным (unit) видом `()`.

Код в приложении 20-14 ссобирается, но пока не создаст ни одного потока. Мы изменили определение `ThreadPool` так, чтобы он содержал вектор образцов `thread::JoinHandle<()>`, объявляли вектор ёмкостью `size`, установили цикл `for`, который будет выполнять некоторый код для создания потоков, и вернули образец `ThreadPool`, содержащий их.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,not_desired_behavior
{{#rustdoc_include ../listings/ch20-web-server/listing-20-14/src/lib.rs:here}}
```

<span class="caption">Приложение 20-14: Создание вектора в <code>ThreadPool</code> для хранения потоков</span>

Мы включили `std::thread` в область видимости библиотечного ящика, потому что мы используем `thread::JoinHandle` в качестве вида элементов вектора в `ThreadPool`.

После получения корректного значения size, наш `ThreadPool` создаёт новый вектор, который может содержать `size` элементов. Функция `with_capacity` выполняет ту же задачу, что и `Vec::new`, но с важным отличием: она заранее выделяет необходимый объём памяти в векторе. Поскольку мы знаем, что нам нужно хранить `size` элементов в векторе, предварительное выделение памяти для этих элементов будет немного более эффективным, чем использование `Vec::new`, при котором размер вектора будет увеличиваться по мере вставки элементов.

Если вы снова запустите приказ `cargo check`, она должна завершиться успешно.

#### Структура `Worker`, ответственная за отправку кода из `ThreadPool` в поток

Мы целенаправленно оставили примечание в цикле `for` в Приложении 20-14 по поводу создания потоков. Сейчас мы разберёмся, как на самом деле создаются потоки. Обычная библиотека предоставляет `thread::spawn` для создания потоков, причём `thread::spawn` ожидает получить некоторый код, который поток должен выполнить, как только он будет создан. Однако в нашем случае мы хотим создавать потоки и заставлять их *ожидать* код, который мы будем передавать им позже. Реализация потоков в встроенной библиотеке не предоставляет никакого способа сделать это, мы должны реализовать это вручную.

Мы будем реализовывать это поведение, добавив новую структуру данных между `ThreadPool` и потоками, которая будет управлять этим новым поведением. Мы назовём эту структуру <code>Worker</code> ("работник"), это общепринятое имя в реализации объединений. Работник берёт код, который нужно выполнить, и запускает этот код внутри рабочего потока. Представьте людей, работающих на кухне ресторана: работники ожидают, пока не поступят заказы от клиентов, а затем они несут ответственность за принятие этих заказов и их выполнение.

Вместо того чтобы хранить вектор образцов `JoinHandle<()>` в объединении потоков, мы будем хранить образцы структуры `Worker`. Каждый `Worker` будет хранить один образец `JoinHandle<()>`. Затем мы реализуем способ у `Worker`, который будет принимать замыкание и отправлять его в существующий поток для выполнения. Для того чтобы мы могли различать работники в объединении при логировании или отладке, мы также присвоим каждому работнику `id`.

Вот как выглядит новая последовательность действий, которые будут происходить при создании `ThreadPool`. Мы реализуем код, который будет отправлять замыкание в поток, после того, как у нас будет `Worker` , заданный следующим образом:

1. Определим структуру `Worker`, которая содержит `id` и `JoinHandle<()>`.
2. Изменим `ThreadPool`, чтобы он содержал вектор образцов `Worker`.
3. Определим функцию `Worker::new`, которая принимает номер `id` и возвращает образец `Worker`, который содержит `id` и поток, порождённый с пустым замыканием.
4. В `ThreadPool::new` используем счётчик цикла `for` для генерации `id`, создаём новый `Worker` с этим `id` и сохраняем образец "работника" в вектор.

Если вы готовы принять вызов, попробуйте реализовать эти изменения самостоятельно, не глядя на код в приложении 20-15.

Готовы? Вот приложение 20-15 с одним из способов сделать указанные ранее изменения.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-15/src/lib.rs:here}}
```

<span class="caption">Приложение 20-15: Изменение <code>ThreadPool</code> для хранения образцов <code>Worker</code> вместо непосредственного хранения потоков</span>

Мы изменили название поля в `ThreadPool` с `threads` на `workers`, поскольку теперь оно содержит образцы `Worker` вместо образцов `JoinHandle<()>`. Мы используем счётчик в цикле `for` для передачи цифрового определителя в качестве переменной `Worker::new`, и сохраняем каждый новый `Worker` в векторе с именем `workers`.

Внешний код (вроде нашего сервера в *src/bin/main.rs*) не обязательно должен знать подробности реализации, касающиеся использования структуры `Worker` внутри `ThreadPool`, поэтому мы делаем структуру `Worker` и её функцию `new` приватными. Функция `Worker::new` использует заданный нами `id` и сохраняет образец `JoinHandle<()>`, который создаётся при порождении нового потока с пустым замыканием.

>  Примечание: Если операционная система не может создать поток из-за нехватки системных ресурсов, `thread::spawn` со сбоем завершится. Это приведёт к со сбоемму завершению нашего сервера целиком, даже если некоторые потоки были созданы успешно. Для простоты будем считать, что нас устраивает такое поведение, но в существующей реализации объединения потоков вы, вероятно, захотите использовать [`std::thread::Builder`]<!-- ignore --> и его способ [`spawn`]<!-- ignore -->, который вместо этого возвращает `Result` .
>

Этот код ссобирается и будет хранить количество образцов `Worker`, которое мы указали в качестве переменной функции `ThreadPool::new`. Но мы всё *ещё* не обрабатываем замыкание, которое мы получаем в способе `execute`. Давайте посмотрим, как это сделать далее.

#### Отправка запросов в потоки через потоки

Следующая неполадка, с которой мы будем бороться, заключается в том, что замыкания, переданные в `thread::spawn` абсолютно ничего не делают. Сейчас мы получаем замыкание, которое хотим выполнить, в способе `execute`. Но мы должны передать какое-то замыкание в способ `thread::spawn`, при создании каждого `Worker`  во время создания `ThreadPool`.

Мы хотим, чтобы вновь созданные структуры `Worker` извлекали код для запуска из очереди, хранящейся в `ThreadPool` и отправляли этот код в свой поток для выполнения.

потоки (channels), простой способ связи между двумя потоками, с которыми мы познакомились в главе 16, кажется наилучше подойдут для этого сценария. Мы будем использовать поток в качестве очереди заданий, а приказ `execute` отправит задание из `ThreadPool` образцам <code>Worker</code>, которые будут отправлять задание в свой поток. Расчет таков:

1. `ThreadPool` создаст поток и будет хранить отправитель.
2. Каждый `Worker` будет хранить приёмник.
3. Мы создадим новую структуру `Job`, которая будет хранить замыкания, которые мы хотим отправить в поток.
4. Способ `execute` отправит задание, которое он хочет выполнить, в отправляющую сторону потока.
5. В своём потоке `Worker` будет замкнуто опрашивать принимающую сторону потока и выполнять замыкание любого задания, которое он получит.

Давайте начнём с создания потока в `ThreadPool::new` и удержания отправляющей стороны в образце `ThreadPool`, как показано в приложении 20-16. В структуре `Job` сейчас ничего не содержится, но это будет вид элемента, который мы отправляем в поток.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-16/src/lib.rs:here}}
```

<span class="caption">Приложение 20-16: Модификация <code>ThreadPool</code> для хранения отправляющей части потока, который отправляет образцы <code>Job</code></span>

В `ThreadPool::new` мы создаём наш новый поток и сохраняем в объединении его отправляющую сторону. Код успешно ссобирается.

Давайте попробуем передавать принимающую сторону потока каждому "работнику" (структуре Worker), когда объединениепотоков создаёт поток. Мы знаем, что хотим использовать получающую часть потока в потоке, порождаемым "работником", поэтому мы будем ссылаться на свойство `receiver` в замыкании. Код 20-17 пока не собирается.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,does_not_compile
{{#rustdoc_include ../listings/ch20-web-server/listing-20-17/src/lib.rs:here}}
```

<span class="caption">Приложение 20-17: Передача принимающей части потока "работникам"</span>

Мы внесли несколько небольших и простых изменений: мы передаём принимающую часть потока в `Worker::new`, а затем используем его внутри замыкания.

При попытке проверить код, мы получаем ошибку:

```console
{{#include ../listings/ch20-web-server/listing-20-17/output.txt}}
```

Код пытается передать `receiver` нескольким образцам `Worker`. Это не сработает, поскольку, как вы можете помнить из главы 16: реализация потока, которую предоставляет Ржавчина - несколько *производителей*, один *потребитель*. Это означает, что мы не можем просто клонировать принимающую сторону потока, чтобы исправить этот код. Кроме этого, мы не хотим отправлять одно и то же сообщение нескольким потребителям, поэтому нам нужен единый список сообщений для множества обработчиков, чтобы каждое сообщение обрабатывалось лишь один раз.

Кроме того, удаление задачи из очереди потока включает изменение `receiver`, поэтому потокам необходим безопасный способ делиться и изменять `receiver`, в противном случае мы можем получить условия гонки (как описано в главе 16).

Вспомните умные указатели, которые обсуждались в главе 16: чтобы делиться владением между несколькими потоками и разрешать потокам изменять значение, нам нужно использовать вид `Arc<Mutex<T>>`. Вид `Arc` позволит нескольким "работникам" владеть получателем (receiver), а `Mutex` заверяет что только один "работник" сможет получить задание (job) от получателя за раз. Приложение 20-18 показывает изменения, которые мы должны сделать.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-18/src/lib.rs:here}}
```

<span class="caption">Приложение 20-18. Совместное использование приёмника в "работниках" с применением <code>Arc</code> и <code>Mutex</code></span>

В `ThreadPool::new` мы помещаем принимающую сторону потока внутрь `Arc` и `Mutex`. Для каждого нового "работника" мы клонируем `Arc`, чтобы увеличить счётчик ссылок так, что "работники" могут разделять владение принимающей стороной потока.

С этими изменениями код собирается! Мы подбираемся к цели!

#### Реализация способа `execute`

Давайте реализуем наконец способ `execute` у структуры `ThreadPool`. Мы также изменим вид `Job` со структуры на псевдоним вида для типаж-предмета. который будет содержать вид замыкания, принимаемый способом `execute`. Как описано в разделе ["Создание родственных вида с помощью псевдонимов типа"](ch19-04-advanced-types.html#creating-type-synonyms-with-type-aliases)<!-- ignore --> главы 19, псевдонимы видов позволяют делать длинные виды короче, облегчая их использование. Посмотрите на приложение 20-19.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-19/src/lib.rs:here}}
```

<span class="caption">Приложение 20-19: Создание псевдонима вида <code>Job</code> для указателя <code>Box</code>, содержащего каждое замыкание и затем отправляющее задание (job) в поток</span>

После создания нового образца `Job` с замыканием, полученным в `execute`, мы посылаем его через отправляющий конец потока. На тот случай, если отправка не удастся, вызываем `unwrap` у `send`. Это может произойти, например, если мы остановим выполнение всех наших потоков, что означает, что принимающая сторона прекратила получать новые сообщения. На данный мгновение мы не можем остановить выполнение наших потоков: наши потоки будут функционировать до тех пор, пока существует объединение Причина, по которой мы используем `unwrap`, заключается в том, что, хотя мы знаем, что сбой не произойдёт, сборщик этого не знает.

Но мы ещё не закончили! В "работнике" (worker) наше замыкание, переданное в `thread::spawn` все ещё *ссылается* только на принимающую сторону потока. Вместо этого нам нужно, чтобы замыкание работало в бесконечном цикле, запрашивая задание у принимающей части потока и выполняя задание, когда оно принято. Давайте внесём изменения, показанные в приложении 20-20 внутри `Worker::new`.

<span class="filename">Файл: src/lib.rs</span>

```rust,noplayground
{{#rustdoc_include ../listings/ch20-web-server/listing-20-20/src/lib.rs:here}}
```

<span class="caption">Приложение 20-20: Получение и выполнение заданий в потоке "работника"</span>

Здесь мы сначала вызываем `lock` у `receiver`, чтобы получить мьютекс, а затем вызываем `unwrap`, чтобы со сбоем завершить работу при любых ошибках. Захват блокировки может завершиться неудачей, если мьютекс находится в *отравленном* состоянии (poisoned state), что может произойти, если какой-то другой поток завершился со сбоем, удерживая блокировку, вместо снятия блокировки. В этой случаи вызвать `unwrap` для со сбоемго завершения потока вполне оправдано. Не стесняйтесь заменить `unwrap` на `expect` с сообщением об ошибке, которое имеет для вас значение.

Если мы получили блокировку мьютекса, мы вызываем `recv`, чтобы получить `Job` из потока. Последний вызов `unwrap` позволяет миновать любые ошибки, которые могут возникнуть, если поток, управляющий отправитель, прекратил функционировать, подобно тому, как способ `send` возвращает `Err`, если получатель не принимает сообщение.

Вызов `recv` - блокирующий, поэтому пока задач нет, текущий поток будет ждать, пока задача не появится. `Mutex<T>` заверяет, что только один поток `Worker` за раз попытается запросить задачу.

Наш объединениепотоков теперь находится в рабочем состоянии! Выполните `cargo run` и сделайте несколько запросов:

<!-- manual-regeneration
cd listings/ch20-web-server/listing-20-20
cargo run
make some requests to 127.0.0.1:7878
Can't automate because the output depends on making requests
-->

```console
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
warning: field is never read: `workers`
 --> src/lib.rs:7:5
  |
7 |     workers: Vec<Worker>,
  |     ^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: field is never read: `id`
  --> src/lib.rs:48:5
   |
48 |     id: usize,
   |     ^^^^^^^^^

warning: field is never read: `thread`
  --> src/lib.rs:49:5
   |
49 |     thread: thread::JoinHandle<()>,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: `hello` (lib) generated 3 warnings
    Finished dev [unoptimized + debuginfo] target(s) in 1.40s
     Running `target/debug/hello`
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
```

Успех! Теперь у нас есть объединениепотоков, который обрабатывает соединения не согласованно. Никогда не создаётся более четырёх потоков, поэтому наша система не будет перегружена, если сервер получит много запросов. Если мы отправим запрос ресурса */sleep*, сервер сможет обслуживать другие запросы, обрабатывая их в другом потоке.

> Примечание: если вы запросите */sleep* в нескольких окнах браузера одновременно, они могут загружаться по одному, с интервалами в 5 секунд. Некоторые веб-браузеры выполняют несколько образцов одного и того же запроса последовательно из-за кэширования. Такое ограничение не связано с работой нашего веб-сервера.

После изучения цикла `while let` в главе 18 вы можете удивиться, почему мы не написали код рабочего потока (worker thread), как показано в приложении 20-22.

<span class="filename">Файл: src/lib.rs</span>

```rust,ignore,not_desired_behavior
{{#rustdoc_include ../listings/ch20-web-server/listing-20-21/src/lib.rs:here}}
```

<span class="caption">Приложение 20-22: Иная реализация <code>Worker::new</code> с использованием <code>while let</code></span>

Этот код собирается и запускается, но не даёт желаемого поведения: медленный запрос всё равно приведёт к тому, что другие запросы будут ждать обработки. Причина здесь несколько тоньше: структура `Mutex` не имеет публичного способа `unlock`, так как владение блокировкой основано на времени жизни `MutexGuard<T>` внутри `LockResult<MutexGuard<T>>`, которое возвращает способ `lock`. Во время сборки анализатор заимствований может проследить за выполнением правила, согласно которому к ресурсу, охраняемому `Mutex`, нельзя получить доступ пока мы удерживаем блокировку. Однако в этой реализация мы также можем получить случай, когда блокировка будет удерживаться дольше, чем предполагалось, если мы не будем внимательно учитывать время жизни `MutexGuard<T>`.

Код в приложении 20-20, использующий `let job = receiver.lock().unwrap().recv().unwrap();` работает, потому что при использовании `let` любые промежуточные значения, используемые в выражении справа от знака равенства, немедленно уничтожаются после завершения указания `let`. Однако `while let` (и `if let` и `match`) не удаляет временные значения до конца связанного раздела. Таким образом, в приложении 20-21 блокировка не снимается в течение всего времени вызова `job()`, что означает, что другие работники не могут получать задания.


["Целочисленные виды"]: ch03-02-data-types.html#integer-types
[`std::thread::Builder`]: ../std/thread/struct.Builder.html
[`spawn`]: ../std/thread/struct.Builder.html#method.spawn